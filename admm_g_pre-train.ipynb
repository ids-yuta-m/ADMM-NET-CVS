{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.3.1\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.autograd import Function\n",
    "import scipy.io as scio\n",
    "from scipy import io\n",
    "\n",
    "class Imgdataset(Dataset):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        super(Imgdataset, self).__init__()\n",
    "        self.data = []\n",
    "        if os.path.exists(path):\n",
    "            groung_truth_path = path + '/gt_gray'\n",
    "            #groung_truth_path = path + '/gt_gray_flip-20240919T013623Z-001/gt_gray_flip'\n",
    "\n",
    "            if os.path.exists(groung_truth_path):\n",
    "                groung_truth = os.listdir(groung_truth_path)\n",
    "                self.data = [{'groung_truth': groung_truth_path + '/' + groung_truth[i]} for i in\n",
    "                             range(len(groung_truth))]\n",
    "            else:\n",
    "                raise FileNotFoundError('path doesnt exist!')\n",
    "        else:\n",
    "            raise FileNotFoundError('path doesnt exist!')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        groung_truth = self.data[index][\"groung_truth\"]\n",
    "\n",
    "        gt = scio.loadmat(groung_truth)\n",
    "        if \"patch_save_gray\" in gt:\n",
    "            gt = torch.from_numpy(gt['patch_save_gray'])\n",
    "        elif \"p1\" in gt:\n",
    "            gt = torch.from_numpy(gt['p1'] / 255)\n",
    "        elif \"p2\" in gt:\n",
    "            gt = torch.from_numpy(gt['p2'] / 255)\n",
    "        elif \"p3\" in gt:\n",
    "            gt = torch.from_numpy(gt['p3'] / 255)\n",
    "\n",
    "        gt = gt.permute(2, 0, 1)\n",
    "\n",
    "        return gt\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class double_conv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.d_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.d_conv(x)\n",
    "        return x\n",
    "\n",
    "class Unet(nn.Module):\n",
    "\n",
    "    def __init__(self,in_ch, out_ch):\n",
    "        super(Unet, self).__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(in_ch, 32)\n",
    "        self.dconv_down2 = double_conv(32, 64)\n",
    "        self.dconv_down3 = double_conv(64, 128)       \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.upsample1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.dconv_up2 = double_conv(64 + 64, 64)\n",
    "        self.dconv_up1 = double_conv(32 + 32, 32)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(32, out_ch, 1)\n",
    "        self.afn_last = nn.Tanh()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        inputs = x\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "\n",
    "        \n",
    "        x = self.upsample2(conv3)        \n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "        \n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample1(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)       \n",
    "\n",
    "        x = self.dconv_up1(x)  \n",
    "        \n",
    "        x = self.conv_last(x)\n",
    "        x = self.afn_last(x)\n",
    "        out = x + inputs\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class double_conv3d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(double_conv3d, self).__init__()\n",
    "        self.d_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.d_conv(x)\n",
    "        return x\n",
    "\n",
    "class Unet3d(nn.Module):\n",
    "\n",
    "    def __init__(self,in_ch, out_ch):\n",
    "        super(Unet3d, self).__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv3d(in_ch, 32)\n",
    "        self.dconv_down2 = double_conv3d(32, 64)\n",
    "        self.dconv_down3 = double_conv3d(64, 128)       \n",
    "\n",
    "        self.maxpool = nn.MaxPool3d(2)\n",
    "        self.upsample2 = nn.Sequential(\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.upsample1 = nn.Sequential(\n",
    "            nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.dconv_up2 = double_conv3d(64 + 64, 64)\n",
    "        self.dconv_up1 = double_conv3d(32 + 32, 32)\n",
    "        \n",
    "        self.conv_last = nn.Conv3d(32, out_ch, 1)\n",
    "        self.afn_last = nn.Tanh()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        inputs = x\n",
    "        #print('inputsize:{}'.format(x.shape))\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        #print('conv1size:{}'.format(conv1.shape))\n",
    "        \n",
    "        x = self.maxpool(conv1)\n",
    "        #print('maxpoolsize:{}'.format(x.shape))\n",
    "        \n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        #print('conv2size:{}'.format(conv2.shape))\n",
    "        \n",
    "        x = self.maxpool(conv2)\n",
    "        #print('maxpool2size:{}'.format(x.shape))\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        #print('conv3size:{}'.format(conv3.shape))\n",
    "\n",
    "        \n",
    "        x = self.upsample2(conv3)\n",
    "        #print('x1:{}'.format(x.shape))        \n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "        #print('x2:{}'.format(x.shape))        \n",
    "        x = self.dconv_up2(x)\n",
    "        #print('x3:{}'.format(x.shape))        \n",
    "        x = self.upsample1(x)        \n",
    "        #print('x4:{}'.format(x.shape))        \n",
    "        x = torch.cat([x, conv1], dim=1)      \n",
    "        #print('x5:{}'.format(x.shape))         \n",
    "\n",
    "        x = self.dconv_up1(x)  \n",
    "        #print('x6:{}'.format(x.shape))        \n",
    "        \n",
    "        x = self.conv_last(x)\n",
    "        x = self.afn_last(x)\n",
    "        out = x + inputs\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.autograd import Function\n",
    "from scipy import io\n",
    "\n",
    "\n",
    "# シャッタパターン読み込み\n",
    "def generate_masks(mask_path,mask_name):\n",
    "    mask = scio.loadmat(mask_path + '/' + mask_name)\n",
    "    mask = mask['ExpPtn']\n",
    "    #print(mask.shape)\n",
    "    mask = np.transpose(mask, [2, 0, 1])\n",
    "    mask_s = np.sum(mask, axis=0)\n",
    "    index = np.where(mask_s == 0)\n",
    "    mask_s[index] = 1\n",
    "    mask_s = mask_s.astype(np.uint8)\n",
    "    mask = torch.from_numpy(mask)\n",
    "    mask = mask.float()\n",
    "    mask = mask.cuda()\n",
    "    mask_s = torch.from_numpy(mask_s)\n",
    "    mask_s = mask_s.float()\n",
    "    mask_s = mask_s.cuda()\n",
    "    return mask, mask_s\n",
    "\n",
    "def time2file_name(time):\n",
    "    year = time[0:4]\n",
    "    month = time[5:7]\n",
    "    day = time[8:10]\n",
    "    hour = time[11:13]\n",
    "    minute = time[14:16]\n",
    "    second = time[17:19]\n",
    "    time_filename = year + '_' + month + '_' + day + '_' + hour + '_' + minute + '_' + second\n",
    "    return time_filename\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarizeHadamardFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight):\n",
    "        ctx.save_for_backward(input, weight)\n",
    "        tmp_zero = torch.zeros(weight.shape).to(weight.device)\n",
    "        tmp_one = torch.ones(weight.shape).to(weight.device)\n",
    "        weight_b = torch.where(weight>0, tmp_one, tmp_zero)\n",
    "        output = input * weight_b\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, weight = ctx.saved_tensors\n",
    "        tmp_zero = torch.zeros(weight.shape).to(weight.device)\n",
    "        tmp_one = torch.ones(weight.shape).to(weight.device)\n",
    "        weight_b = torch.where(weight>0, tmp_one, tmp_zero)\n",
    "        grad_input = grad_weight = None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = grad_output * weight_b\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = grad_output * input\n",
    "        return grad_input, grad_weight\n",
    "\n",
    "class LearnableMask(nn.Module):\n",
    "    def __init__(self, t=16, s=256):\n",
    "        super().__init__()\n",
    "        self.t = t\n",
    "        self.s = s\n",
    "        self.weight = nn.Parameter(torch.Tensor(t, s, s))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.stdv = torch.sqrt(torch.tensor(1.5 / (self.s * self.s * self.t)))\n",
    "        self.weight.data.uniform_(-self.stdv, self.stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return BinarizeHadamardFunction.apply(input, self.weight)\n",
    "\n",
    "    def get_binary_mask(self):\n",
    "        with torch.no_grad():\n",
    "            return torch.where(self.weight > 0, \n",
    "                             torch.ones_like(self.weight), \n",
    "                             torch.zeros_like(self.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#再構成モデル　DMM\n",
    "class ADMM_net(nn.Module):\n",
    "\n",
    "    def __init__(self, t=16, s=256):\n",
    "        super(ADMM_net, self).__init__()\n",
    "        self.mask = LearnableMask(t=t, s=s)\n",
    "        self.unet1 = Unet(16, 16)\n",
    "        self.unet2 = Unet(16, 16)\n",
    "        self.unet3 = Unet(16, 16)\n",
    "        self.unet4 = Unet(16, 16)\n",
    "        self.unet5 = Unet(16, 16)\n",
    "        self.unet6 = Unet(16, 16)\n",
    "        self.unet7 = Unet(16, 16)\n",
    "        self.unet8 = Unet(16, 16)\n",
    "        self.unet9 = Unet(16, 16)   \n",
    "        self.gamma1 = torch.nn.Parameter(torch.Tensor([0]))\n",
    "        self.gamma2 = torch.nn.Parameter(torch.Tensor([0]))\n",
    "        self.gamma3 = torch.nn.Parameter(torch.Tensor([0]))\n",
    "        self.gamma4 = torch.nn.Parameter(torch.Tensor([0]))\n",
    "        self.gamma5 = torch.nn.Parameter(torch.Tensor([0]))\n",
    "        self.gamma6 = torch.nn.Parameter(torch.Tensor([0]))\n",
    "        self.gamma7 = torch.nn.Parameter(torch.Tensor([0]))\n",
    "        self.gamma8 = torch.nn.Parameter(torch.Tensor([0]))\n",
    "        self.gamma9 = torch.nn.Parameter(torch.Tensor([0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Generate measurement using learnable mask\n",
    "        maskt = self.mask(x)\n",
    "        y = torch.sum(maskt, dim=1)\n",
    "        \n",
    "        # Get binary mask for reconstruction\n",
    "        binary_mask = self.mask.get_binary_mask()\n",
    "        Phi = binary_mask.expand([x.shape[0], 16, 256, 256])\n",
    "        Phi_s = torch.sum(binary_mask, dim=0).expand([x.shape[0], 256, 256])\n",
    "\n",
    "        # ADMM reconstruction\n",
    "        x_list = []\n",
    "        theta = self.At(y, Phi)\n",
    "        b = torch.zeros_like(Phi)\n",
    "\n",
    "        # 9 stages of reconstruction\n",
    "        x_list = []\n",
    "        theta = self.At(y,Phi)\n",
    "        b = torch.zeros_like(Phi)\n",
    "        ### 1-3\n",
    "        yb = self.A(theta+b,Phi)\n",
    "        x = theta+b + self.At(torch.div(y-yb,Phi_s+self.gamma1),Phi)\n",
    "        x1 = x-b\n",
    "        theta = self.unet1(x1)\n",
    "        b = b- (x-theta)\n",
    "        x_list.append(theta)\n",
    "        yb = self.A(theta+b,Phi)\n",
    "        x = theta+b + self.At(torch.div(y-yb,Phi_s+self.gamma2),Phi)\n",
    "        x1 = x-b\n",
    "        theta = self.unet2(x1)\n",
    "        b = b- (x-theta)\n",
    "        x_list.append(theta)\n",
    "        yb = self.A(theta+b,Phi)\n",
    "        x = theta+b + self.At(torch.div(y-yb,Phi_s+self.gamma3),Phi)\n",
    "        x1 = x-b\n",
    "        theta = self.unet3(x1)\n",
    "        b = b- (x-theta)\n",
    "        x_list.append(theta)\n",
    "        ### 4-6\n",
    "        yb = self.A(theta+b,Phi)\n",
    "        x = theta+b + self.At(torch.div(y-yb,Phi_s+self.gamma4),Phi)\n",
    "        x1 = x-b\n",
    "        theta = self.unet4(x1)\n",
    "        b = b- (x-theta)\n",
    "        x_list.append(theta)\n",
    "        yb = self.A(theta+b,Phi)\n",
    "        x = theta+b + self.At(torch.div(y-yb,Phi_s+self.gamma5),Phi)\n",
    "        x1 = x-b\n",
    "        theta = self.unet5(x1)\n",
    "        b = b- (x-theta)\n",
    "        x_list.append(theta)\n",
    "        yb = self.A(theta+b,Phi)\n",
    "        x = theta+b + self.At(torch.div(y-yb,Phi_s+self.gamma6),Phi)\n",
    "        x1 = x-b\n",
    "        theta = self.unet6(x1)\n",
    "        b = b- (x-theta)\n",
    "        x_list.append(theta)\n",
    "        ### 7-9\n",
    "        yb = self.A(theta+b,Phi)\n",
    "        x = theta+b + self.At(torch.div(y-yb,Phi_s+self.gamma7),Phi)\n",
    "        x1 = x-b\n",
    "        theta = self.unet7(x1)\n",
    "        b = b- (x-theta)\n",
    "        x_list.append(theta)\n",
    "        yb = self.A(theta+b,Phi)\n",
    "        x = theta+b + self.At(torch.div(y-yb,Phi_s+self.gamma8),Phi)\n",
    "        x1 = x-b\n",
    "        theta = self.unet8(x1)\n",
    "        b = b- (x-theta)\n",
    "        x_list.append(theta)\n",
    "        yb = self.A(theta+b,Phi)\n",
    "        x = theta+b + self.At(torch.div(y-yb,Phi_s+self.gamma9),Phi)\n",
    "        x1 = x-b\n",
    "        theta = self.unet9(x1)\n",
    "        b = b- (x-theta)\n",
    "        x_list.append(theta)\n",
    "\n",
    "        return x_list\n",
    "    \n",
    "    def A(self, x,Phi):\n",
    "        temp = x*Phi\n",
    "        y = torch.sum(temp,1)\n",
    "        return y\n",
    "\n",
    "    def At(self, y,Phi):\n",
    "\n",
    "        temp = torch.unsqueeze(y, 1).repeat(1,Phi.shape[1], 1,1)\n",
    "        x = temp*Phi\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Epoch 1\n",
      "Loss: 0.109909\n",
      "Time: 169.80s\n",
      "Test result: 21.2430\n",
      "Validation result: 21.0099\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 331\u001b[0m\n\u001b[1;32m    316\u001b[0m mask_name_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhitomirandom256x256\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhitomirandom256x256_rl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom256x256_udrl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m ]\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mask_name \u001b[38;5;129;01min\u001b[39;00m mask_name_list:\n\u001b[0;32m--> 331\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0016\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 278\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(mask_lr, recon_lr, mask_name)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(last_train \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, last_train \u001b[38;5;241m+\u001b[39m max_iter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    276\u001b[0m     psnr \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 278\u001b[0m     loss, time, binary_mask \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_explicit_mask_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecon_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     pred, psnr_epoch \u001b[38;5;241m=\u001b[39m test(network, test_path1, epoch, recon_path, psnr_epoch, psnr)\n\u001b[1;32m    281\u001b[0m     psnr_mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(psnr_epoch[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[7], line 173\u001b[0m, in \u001b[0;36mtrain_with_explicit_mask_optimization\u001b[0;34m(network, train_loader, epoch, mask_lr, recon_lr, device)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# マスクに関する正則化項（オプション）\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m#mask_sparsity = 0.01 * torch.mean(torch.abs(network.mask.weight))\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m#mask_smoothness = 0.01 * compute_smoothness(network.mask.weight)\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# 総損失\u001b[39;00m\n\u001b[1;32m    171\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m recon_loss  \u001b[38;5;66;03m#+ mask_sparsity + mask_smoothness\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# マスクと再構成ネットワークの更新を分離\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m#mask_optimizer.step()\u001b[39;00m\n\u001b[1;32m    177\u001b[0m recon_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# maskがbayer_randomで固定バージョン(RGB画像版と対照)\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import scipy.io as scio\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception('NO GPU!')\n",
    "\n",
    "data_path = r\"./data/\"\n",
    "\n",
    "test_path1 = r\"./data/ktestdata2_gray\"\n",
    "#test_path1 = r\"./data/test_gray\"\n",
    "val_path1 = r\"./data/valdata_gray\"\n",
    "result_path1 = r\"./result/ADMM_gray\"\n",
    "mask_path = r\"./mask\"\n",
    "\n",
    "#mask_name = 'bayer_random256x256'  #完全ランダムパターン\n",
    "# mask_name = 'bayer_hitomirandom256x256'  #hitomiの制約ありパターン\n",
    "# mask_name = 'bayer_hamaphotorandom256x256'  #ハマホトカメラ用制約ありパターン\n",
    "#mask_name ='allOne_gray'\n",
    "#mask, mask_s = generate_masks(mask_path,mask_name)\n",
    "\n",
    "last_train = 0\n",
    "model_save_filename = ''\n",
    "max_iter = 100\n",
    "batch_size = 4\n",
    "learning_rate = 0.0016\n",
    "stage_num = 9\n",
    "mode = 'train'  # train or test\n",
    "\n",
    "dataset = Imgdataset(data_path)\n",
    "train_data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#if last_train != 0:\n",
    "#    network = torch.load(\n",
    "#        './model/' + 'monochrome/' + model_save_filename + \"/model_epoch_{}.pth\".format(last_train))\n",
    "\n",
    "def compute_smoothness(tensor):\n",
    "    diff_h = torch.abs(tensor[:, :, 1:] - tensor[:, :, :-1])\n",
    "    diff_w = torch.abs(tensor[:, 1:, :] - tensor[:, :-1, :])\n",
    "    \n",
    "    # パディングして元のサイズに戻す\n",
    "    diff_h = torch.nn.functional.pad(diff_h, (0, 1, 0, 0))\n",
    "    diff_w = torch.nn.functional.pad(diff_w, (0, 0, 0, 1))\n",
    "    \n",
    "    return torch.mean(diff_h + diff_w)\n",
    "\n",
    "def test(network, test_path, epoch, recon_path, psnr_epoch, psnr):\n",
    "    network.eval()\n",
    "    test_list = os.listdir(test_path)\n",
    "    psnr_sample = torch.zeros(len(test_list))\n",
    "    pred = []\n",
    "    #compression_rate_checked = False\n",
    "    \n",
    "    for i in range(len(test_list)):\n",
    "        pic = scio.loadmat(test_path + '/' + test_list[i])\n",
    "\n",
    "        if \"patch_save_gray\" in pic:\n",
    "            pic = pic['patch_save_gray']\n",
    "#         pic = pic / 255\n",
    "        elif \"y\" in pic:\n",
    "            pic = pic['y']\n",
    "        elif \"p1\" in pic:\n",
    "            pic = pic['p1']\n",
    "        elif \"p2\" in pic:\n",
    "            pic = pic['p2']\n",
    "        elif \"p3\" in pic:\n",
    "            pic = pic['p3']\n",
    "        #print(pic)\n",
    "        pic = np.transpose(pic, [2,0,1])\n",
    "        pic0 = torch.from_numpy(pic).cuda().float()\n",
    "        pic0 = pic0.unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out_pic_list = network(pic0)\n",
    "            #print('y.shape:{}'.format(y.shape))\n",
    "            #print('Phi.shape:{}'.format(Phi.shape))\n",
    "            #print('Phi_s.shape:{}'.format(Phi_s.shape))\n",
    "            out_pic = out_pic_list[-1]\n",
    "            \n",
    "            #print('out_pic:{}'.format(out_pic.shape))\n",
    "\n",
    "\n",
    "            psnr_1 = 10 * torch.log10(1 / criterion(out_pic, pic0))\n",
    "\n",
    "            psnr_sample[i] = psnr_1\n",
    "            \n",
    "            if test_path == test_path1:\n",
    "                psnr[test_list[i]] = float(psnr_1)\n",
    "        \n",
    "        pred.append(out_pic.cpu().numpy())\n",
    "        \n",
    "    psnr_epoch.append(psnr_sample)\n",
    "    \n",
    "    if test_path == test_path1:\n",
    "        psnr['test_avg'] = float(torch.mean(psnr_sample))\n",
    "    else:\n",
    "        psnr['val_avg'] = float(torch.mean(psnr_sample))\n",
    "    \n",
    "    return pred, psnr_epoch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_with_explicit_mask_optimization(network, train_loader, epoch, mask_lr, recon_lr, device):\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # マスク用の最適化器と再構成ネットワーク用の最適化器を分離\n",
    "    mask_optimizer = optim.Adam([\n",
    "        {'params': network.mask.parameters(), 'lr': mask_lr}\n",
    "    ])\n",
    "    \n",
    "    recon_optimizer = optim.Adam([\n",
    "        {'params': network.unet1.parameters()},\n",
    "        {'params': network.unet2.parameters()},\n",
    "        {'params': network.unet3.parameters()},\n",
    "        {'params': network.unet4.parameters()},\n",
    "        {'params': network.unet5.parameters()},\n",
    "        {'params': network.unet6.parameters()},\n",
    "        {'params': network.unet7.parameters()},\n",
    "        {'params': network.unet8.parameters()},\n",
    "        {'params': network.unet9.parameters()},\n",
    "        {'params': network.gamma1},\n",
    "        {'params': network.gamma2},\n",
    "        {'params': network.gamma3},\n",
    "        {'params': network.gamma4},\n",
    "        {'params': network.gamma5},\n",
    "        {'params': network.gamma6},\n",
    "        {'params': network.gamma7},\n",
    "        {'params': network.gamma8},\n",
    "        {'params': network.gamma9}\n",
    "    ], lr=recon_lr)\n",
    "    \n",
    "    network.train()\n",
    "    epoch_loss = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    for batch_idx, gt in enumerate(train_loader):\n",
    "        gt = gt.to(device).float()\n",
    "        \n",
    "        # マスクの最適化ステップ\n",
    "        #mask_optimizer.zero_grad()\n",
    "        recon_optimizer.zero_grad()\n",
    "        \n",
    "        outputs = network(gt)\n",
    "        \n",
    "        # 再構成誤差\n",
    "        recon_loss = (torch.sqrt(criterion(outputs[-1], gt)) + \n",
    "                    0.5 * torch.sqrt(criterion(outputs[-2], gt)) + \n",
    "                    0.5 * torch.sqrt(criterion(outputs[-3], gt)))\n",
    "        \n",
    "        # マスクに関する正則化項（オプション）\n",
    "        #mask_sparsity = 0.01 * torch.mean(torch.abs(network.mask.weight))\n",
    "        #mask_smoothness = 0.01 * compute_smoothness(network.mask.weight)\n",
    "        \n",
    "        # 総損失\n",
    "        total_loss = recon_loss  #+ mask_sparsity + mask_smoothness\n",
    "        \n",
    "        total_loss.backward()\n",
    "        \n",
    "        # マスクと再構成ネットワークの更新を分離\n",
    "        #mask_optimizer.step()\n",
    "        recon_optimizer.step()\n",
    "        \n",
    "        epoch_loss += total_loss.item()\n",
    "        \n",
    "        # マスクの制約を適用（オプション）\n",
    "        # with torch.no_grad():\n",
    "        #     # マスクの値を0-1の範囲に制限\n",
    "        #     network.mask.weight.data.clamp_(-1, 1)\n",
    "            \n",
    "        #     # 特定の制約条件を適用（例：各時間ステップでの露光時間の合計を制限）\n",
    "        #     total_exposure = torch.sum(network.mask.get_binary_mask(), dim=(1,2))\n",
    "        #     if torch.any(total_exposure > 128):  # 例：最大露光時間を128に制限\n",
    "        #         scale_factor = 128 / total_exposure\n",
    "        #         network.mask.weight.data *= scale_factor.view(-1, 1, 1)\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    time_taken = time.time() - start_time\n",
    "    print(\"====================================\")\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    print(f\"Loss: {avg_epoch_loss:.6f}\")\n",
    "    print(f\"Time: {time_taken:.2f}s\")\n",
    "\n",
    "    return avg_epoch_loss, time_taken, network.mask.get_binary_mask()\n",
    "    \n",
    "\n",
    "def checkpoint(network, epoch, model_path):\n",
    "    model_out_path = './' + model_path + \"/pre-train_epoch_{}.pth\".format(epoch)\n",
    "    torch.save(network, model_out_path)\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
    "    \n",
    "def savemask(network, epoch, binary_mask, datetime):\n",
    "    exposure_sum = torch.sum(binary_mask, dim=(1,2))\n",
    "    print(f\"Average exposure per frame: {exposure_sum.mean().item():.2f}\")\n",
    "        \n",
    "    # マスクを保存\n",
    "    mask_path = f'./mask_pre-train/{datetime}'\n",
    "    if not os.path.exists(mask_path):\n",
    "        os.makedirs(mask_path)\n",
    "    scio.savemat(mask_path + f\"/mask_epoch_{epoch}.mat\", {\n",
    "        'mask': binary_mask.cpu().numpy(),\n",
    "        'raw_weights': network.mask.weight.detach().cpu().numpy()\n",
    "    }) \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def main(mask_lr, recon_lr, mask_name):\n",
    "    date_time = str(datetime.datetime.now())\n",
    "    date_time = time2file_name(date_time)\n",
    "    recon_path = 'recon' + '/' + 'monochrome' + '/' + mask_name + '/' + date_time\n",
    "    model_path = 'model' + '/' + 'monochrome' + '/' + mask_name + '/' + date_time\n",
    "    result_path = result_path1 + '/' + mask_name + '/' + date_time\n",
    "    \n",
    "    if not os.path.exists(recon_path):\n",
    "        os.makedirs(recon_path)\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    \n",
    "    psnr_epoch = []\n",
    "    val_psnr_epoch = []\n",
    "    result_dict = []\n",
    "    \n",
    "    mask = mask = scio.loadmat('./mask/bayer_'+ mask_name + '.mat')\n",
    "    mask = mask['ExpPtn']\n",
    "    #mask = np.transpose(mask, [2, 0, 1])  # (T, H, W)の形式に変換\n",
    "    mask = torch.from_numpy(mask).float()\n",
    "    \n",
    "    network = ADMM_net().cuda()\n",
    "    #network = torch.load('./model/monochrome/2024_10_23_17_21_26_bayer_random256x256/S9_model_epoch_200.pth', map_location=torch.device('cpu'))\n",
    "    # video_path = \"./data/ktestdata2_gray/gray_3_aerobatics00000_3.mat\"\n",
    "    # model_path = \"./model/monochrome/2024_10_23_17_21_26_bayer_random256x256/S9_model_epoch_200.pth\"\n",
    "    \n",
    "    network.mask.weight.data.copy_(mask)\n",
    "        \n",
    "    # 再構成部分のパラメータのみ更新可能に\n",
    "    # マスクのパラメータを凍結\n",
    "    network.mask.requires_grad_(False)\n",
    "    # 再構成部分のパラメータを更新可能に\n",
    "    network.unet1.requires_grad_(True)\n",
    "    network.unet2.requires_grad_(True)\n",
    "    network.unet3.requires_grad_(True)\n",
    "    network.unet4.requires_grad_(True)\n",
    "    network.unet5.requires_grad_(True)\n",
    "    network.unet6.requires_grad_(True)\n",
    "    network.unet7.requires_grad_(True)\n",
    "    network.unet8.requires_grad_(True)\n",
    "    network.unet9.requires_grad_(True)\n",
    "    network.gamma1.requires_grad_(True)\n",
    "    network.gamma2.requires_grad_(True)\n",
    "    network.gamma3.requires_grad_(True)\n",
    "    network.gamma4.requires_grad_(True)\n",
    "    network.gamma5.requires_grad_(True)\n",
    "    network.gamma6.requires_grad_(True)\n",
    "    network.gamma7.requires_grad_(True)\n",
    "    network.gamma8.requires_grad_(True)\n",
    "    network.gamma9.requires_grad_(True)\n",
    "    \n",
    "    for epoch in range(last_train + 1, last_train + max_iter + 1):\n",
    "        psnr = {}\n",
    "        \n",
    "        loss, time, binary_mask = train_with_explicit_mask_optimization(network, train_data_loader, epoch, mask_lr, recon_lr, device='cuda')\n",
    "        \n",
    "        pred, psnr_epoch = test(network, test_path1, epoch, recon_path, psnr_epoch, psnr)\n",
    "        psnr_mean = torch.mean(psnr_epoch[-1])\n",
    "        \n",
    "        val_pred, val_psnr_epoch = test(network, val_path1, epoch, recon_path, val_psnr_epoch, psnr)\n",
    "        val_psnr_mean = torch.mean(val_psnr_epoch[-1])\n",
    "        \n",
    "        print(\"Test result: {:.4f}\".format(psnr_mean))\n",
    "        print(\"Validation result: {:.4f}\".format(val_psnr_mean))\n",
    "        \n",
    "        result_dict.append({\n",
    "            'epoch' : epoch,\n",
    "            'lr' : recon_lr,\n",
    "            'loss' : loss,\n",
    "            'time' : time, \n",
    "            'psnr' : psnr\n",
    "        })\n",
    "        \n",
    "        with open(result_path + '/' + 'admm_gray_pre-train_result.json', 'w') as file:\n",
    "                json.dump(result_dict, file, indent=4)\n",
    "        \n",
    "\n",
    "        if (epoch % 10 == 0):\n",
    "\n",
    "            name = recon_path + '/S{}'.format(stage_num) + '_pred_' + '{}_{:.4f}'.format(epoch, psnr_mean) + '.mat'\n",
    "            scio.savemat(name, {'pred': pred})\n",
    "            #savemask(network, epoch, binary_mask, date_time)\n",
    "            checkpoint(network, epoch, model_path)\n",
    "            \n",
    "            \n",
    "        \n",
    "        if (epoch % 10 == 0) and (epoch < 300):\n",
    "            mask_lr = mask_lr*0.95\n",
    "            recon_lr = recon_lr*0.95\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mask_name_list = [\n",
    "        \"hitomirandom256x256\",\n",
    "        \"hitomirandom256x256_rl\",\n",
    "        \"hitomirandom256x256_ud\",\n",
    "        \"hitomirandom256x256_udrl\",\n",
    "        \"hamaphotorandom256x256\",\n",
    "        \"hamaphotorandom256x256_rl\",\n",
    "        \"hamaphotorandom256x256_ud\",\n",
    "        \"hamaphotorandom256x256_udrl\",\n",
    "        \"random256x256\",\n",
    "        \"random256x256_rl\",\n",
    "        \"random256x256_ud\",\n",
    "        \"random256x256_udrl\"\n",
    "    ]\n",
    "    for mask_name in mask_name_list:\n",
    "        main(0.0001, 0.0016, mask_name)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
